---
title: "BG_3MS_KNN"
author: "Benjamin Pope"
date: "3/4/2021"
output: word_document
---

```{r}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = normalizePath("D:/Templates/UW Stuff/Classes/MSBA/Classes/Q4 Models/Tuning/kNN"))
```


```{r}
library(DBI)
library(odbc)
library(data.table)
library(caret)
library(FNN)
library(class)
library(psych)
```

```{r}
setwd("D:/Templates/UW Stuff/Classes/MSBA/Classes/Q4 Models")
df <- read.csv("Config_File.csv")

con <- DBI::dbConnect(odbc::odbc(),
  driver = "PostgreSQL Unicode(x64)",
  database = "TEST",
  UID      = df$UID,
  PWD      = df$PWD,
  server = df$server,
  port = 5432)
```

```{r}
import.census <- dbGetQuery(con, 'select
     bg.bg_geo_id "Block Group ID"
     ,(select avg(bgs.score) from "BG_Score" as bgs where bgs.bg_geo_id=bg.bg_geo_id) "Average Block Group Score"
     ,max(case when dv.sid=\'pop\' then bgd.value Else 0 END) "Population"
     ,max(case when dv.sid=\'pop_MF_3MS\' then bgd.value Else 0 END) "Population: 3 Mile"
     ,max(case when dv.sid=\'hi_tot_3MS\' then bgd.value Else 0 END) "Households: 3 Mile"
    ,max(case when dv.sid=\'M_0_5\' then bgd.value Else 0 END)+max(case when dv.sid=\'F_0_5\' then bgd.value Else 0 END) "Kids under 5"
     ,round(cast((max(case when dv.sid=\'M_0_5\' then bgd.value Else 0 END)+max(case when dv.sid=\'F_0_5\' then bgd.value Else 0 END)) /
        max(case when dv.sid=\'pop\' then bgd.value Else null END) as numeric),3) "Percent Kids under 5"
    ,max(case when dv.sid=\'M_0_5_3MS\' then bgd.value Else 0 END)+max(case when dv.sid=\'F_0_5_3MS\' then bgd.value Else 0 END) "Kids under 5: 3 Mile"
     ,round(cast((max(case when dv.sid=\'M_0_5_3MS\' then bgd.value Else 0 END)+max(case when dv.sid=\'F_0_5_3MS\' then bgd.value Else 0 END)) /
        max(case when dv.sid=\'pop_MF_3MS\' then bgd.value Else null END) as numeric),3) "Percent Kids under 5: 3 Mile"
    ,max(case when dv.sid=\'M_5_9\' then bgd.value Else 0 END)+max(case when dv.sid=\'F_5_9\' then bgd.value Else 0 END) "Kids 5 to 9"
     ,round(cast((max(case when dv.sid=\'M_5_9\' then bgd.value Else 0 END)+max(case when dv.sid=\'F_5_9\' then bgd.value Else 0 END)) /
        max(case when dv.sid=\'pop\' then bgd.value Else null END) as numeric),3) "Percent Kids 5 to 9"
    ,max(case when dv.sid=\'M_5_9_3MS\' then bgd.value Else 0 END)+max(case when dv.sid=\'F_5_9_3MS\' then bgd.value Else 0 END) "Kids 5 to 9: 3 Mile"
    ,round(cast((max(case when dv.sid=\'M_5_9_3MS\' then bgd.value Else 0 END)+max(case when dv.sid=\'F_5_9_3MS\' then bgd.value Else 0 END)) /
         max(case when dv.sid=\'pop_MF_3MS\' then bgd.value Else null END) as numeric),3)  "Percent Kids 5 to 9: 3 Mile"
    ,max(case when dv.sid=\'avg_age\' then bgd.value Else 0 END) "Average Age"
    ,round(cast(sum(case when dv.sid in(\'hi_0_10_3MS\',\'hi_10_15_3MS\',\'hi_15_20_3MS\',\'hi_20_25_3MS\',\'hi_25_30_3MS\',\'hi_30_35_3MS\',\'hi_35_40_3MS\') then bgd.value  else 0 END) /
      max(case when dv.sid=\'hi_tot_3MS\' then bgd.value Else 0 END) as numeric),3) "Household income under 40K: 3 Mile"
    ,round(cast(sum(case when dv.sid in(\'hi_40_45_3MS\',\'hi_45_50_3MS\') then bgd.value  else 0 END) /
      max(case when dv.sid=\'hi_tot_3MS\' then bgd.value Else 0 END) as numeric),3) "Household income 40K to 50K: 3 Mile"
    ,round(cast(sum(case when dv.sid in(\'hi_50_60_3MS\') then bgd.value  else 0 END) /
      max(case when dv.sid=\'hi_tot_3MS\' then bgd.value Else 0 END) as numeric),3) "Household income 50K to 60K: 3 Mile"
    ,round(cast(sum(case when dv.sid in(\'hi_60_75_3MS\') then bgd.value  else 0 END) /
      max(case when dv.sid=\'hi_tot_3MS\' then bgd.value Else 0 END) as numeric),3) "Household income 60K to 75K: 3 Mile"
    ,round(cast(sum(case when dv.sid in(\'hi_75_100_3MS\') then bgd.value  else 0 END) /
      max(case when dv.sid=\'hi_tot_3MS\' then bgd.value Else 0 END) as numeric),3) "Household income 75K to 100K: 3 Mile"
    ,round(cast(sum(case when dv.sid in(\'hi_100_125_3MS\') then bgd.value  else 0 END) /
      max(case when dv.sid=\'hi_tot_3MS\' then bgd.value Else 0 END) as numeric),3) "Household income 100K to 125K: 3 Mile"
    ,round(cast(sum(case when dv.sid in(\'hi_125_150_3MS\') then bgd.value  else 0 END) /
      max(case when dv.sid=\'hi_tot_3MS\' then bgd.value Else 0 END) as numeric),3) "Household income 125K to 150K: 3 Mile"
    ,round(cast(sum(case when dv.sid in(\'hi_150_200_3MS\') then bgd.value  else 0 END) /
      max(case when dv.sid=\'hi_tot_3MS\' then bgd.value Else 0 END) as numeric),3) "Household income 150K to 200K: 3 Mile"
    ,round(cast(sum(case when dv.sid in(\'hi_200_999_3MS\') then bgd.value  else 0 END) /
      max(case when dv.sid=\'hi_tot_3MS\' then bgd.value Else 0 END) as numeric),3) "Household income 200K+: 3 Mile"
from "Block_Group" as bg
left join "BG_Data" as bgd on bg.bg_geo_id = bgd.bg_geo_id
inner join "Demo_Var" as dv on dv.full_variable_id=bgd.variable_id
group by bg.bg_geo_id
having
max(case when dv.sid=\'pop\' then bgd.value Else 0 END) > 0
and max(case when dv.sid=\'hi_tot_3MS\' then bgd.value Else 0 END)>0')
import.census
```

```{r}
#We need to query the variables used for the score as well as the score from the DB

census.scores <- sqldf('SELECT "Block Group ID" AS "Block.Group.ID", "Average Block Group Score" AS "Average.Block.Group.Score", Population, "Population: 3 Mile" AS "Population.3.Mile", "Households: 3 Mile" AS "Households.3.Mile", "Percent Kids under 5" AS "Percent.Kids.under.5", "Percent Kids under 5: 3 Mile" AS "Percent.Kids.under.5.3.Mile", "Percent Kids 5 to 9" AS "Percent.Kids.5.to.9", "Percent Kids 5 to 9: 3 Mile" AS "Percent.Kids.5.to.9.3 Mile", "Average Age" AS "Average.Age", "Household income under 40K: 3 Mile" AS "Household.income.under.40K.3Mile", "Household income 40K to 50K: 3 Mile" AS "Household.income.40K.to.50K.3.Mile", "Household income 50K to 60K: 3 Mile" AS "Household.income.50K.to.60K.3.Mile", "Household income 60K to 75K: 3 Mile" AS "Household.income.60K.to.75K.3.Mile", "Household income 75K to 100K: 3 Mile" AS "Household.income.75K.to.100K.3.Mile", "Household income 100K to 125K: 3 Mile" AS "Household.income.100:.125K.3.Mile", "Household income 125K to 150K: 3 Mile" AS "Household.income.125K.to.150K.3.Mile", "Household income 150K to 200K: 3 Mile" AS "Household.income.150K.to.200K.3.Mile", "Household income 200K+: 3 Mile"  AS "Household.income.200K+.3Mile"FROM "import.census" WHERE "Average Block Group Score" IS NOT NULL')

census.scores
#this is to make an export of the final model output
census.export <- census.scores
```

```{r}
min.max.norm <- function(x) {
  (x - min(x)) / (max(x) - min(x))
}

for (i in 2:length(census.scores)) {
  census.scores[i] <- min.max.norm(census.scores[i])
}

census.scores
```


```{r}

train.index <- sample(row.names(census.scores),0.6*dim(census.scores)[1])
valid.index <- setdiff(row.names(census.scores), train.index)

train.df <- census.scores[train.index,]
valid.df <- census.scores[valid.index,]

k.num <-nrow(train.df)
census.scores.rmse <- data.frame(k = seq(1, k.num, 1), RMSE_value = rep(0, k.num))
# compute knn for different k on validation.

for(i in 1:k.num) {
  knn.pred<- class::knn(train = train.df[,3:19], test = valid.df[,3:19], cl = train.df[,2],k=i)
  
  census.scores.rmse[i, 2] <- RMSE(as.numeric(as.character(knn.pred)), valid.df[,2])
}

min(census.scores.rmse)
census.scores.rmse

### Looks like k = is the highest consistency 
knn.model <- class::knn(train = train.df[,3:19], test = valid.df[,3:19], cl = train.df[,2],k =8)
confusionMatrix(as.factor(knn.model), as.factor(valid.df$`Average.Block.Group.Score`))
str(valid.df)

RMSE(as.numeric(knn.model), valid.df[,2])

```
```{r}
#Normalize and prepare entire scored set 
census.norm.scores <- rbind(train.df, valid.df)
census.norm.scores
```

```{r}
#We need to query the variables used for the score as well as the score from the DB

new.census.scores <- sqldf('SELECT "Block Group ID" AS "Block.Group.ID", "Average Block Group Score" AS "Average.Block.Group.Score", Population, "Population: 3 Mile" AS "Population.3.Mile", "Households: 3 Mile" AS "Households.3.Mile", "Percent Kids under 5" AS "Percent.Kids.under.5", "Percent Kids under 5: 3 Mile" AS "Percent.Kids.under.5.3.Mile", "Percent Kids 5 to 9" AS "Percent.Kids.5.to.9", "Percent Kids 5 to 9: 3 Mile" AS "Percent.Kids.5.to.9.3 Mile", "Average Age" AS "Average.Age", "Household income under 40K: 3 Mile" AS "Household.income.under.40K.3Mile", "Household income 40K to 50K: 3 Mile" AS "Household.income.40K.to.50K.3.Mile", "Household income 50K to 60K: 3 Mile" AS "Household.income.50K.to.60K.3.Mile", "Household income 60K to 75K: 3 Mile" AS "Household.income.60K.to.75K.3.Mile", "Household income 75K to 100K: 3 Mile" AS "Household.income.75K.to.100K.3.Mile", "Household income 100K to 125K: 3 Mile" AS "Household.income.100:.125K.3.Mile", "Household income 125K to 150K: 3 Mile" AS "Household.income.125K.to.150K.3.Mile", "Household income 150K to 200K: 3 Mile" AS "Household.income.150K.to.200K.3.Mile", "Household income 200K+: 3 Mile"  AS "Household.income.200K+.3Mile"FROM "import.census" WHERE "Average Block Group Score" IS NULL')

new.census.scores
#this is to make an export of the final model output
new.census.export <- new.census.scores
```

```{r}

min.max.norm <- function(x) {
  (x - min(x)) / (max(x) - min(x))
}

for (i in 2:length(new.census.scores)) {
  new.census.scores[i] <- min.max.norm(new.census.scores[i])
}

new.census.scores
```

```{r}
# Predict new records for 

#Set test name
model_id ="3MS_KNN_v.3"

knn.model <- class::knn(train = train.df[,3:19], test = valid.df[,3:19], cl = train.df[,2],k =4)
knn.pred.new <- class::knn(train = census.norm.scores[,3:19], test = new.census.scores[,3:19], cl = census.norm.scores[,2] ,k=8)
summary(knn.pred.new)
knn.model
```

```{r}
### Set up output file

new.census.export$Score.Predict <- knn.pred.new
new.census.export

write.csv(new.census.export,"D:/Templates/UW Stuff/Classes/MSBA/Classes/Q4 Models/Tuning/kNN\\bg_KNN_output_v.3.csv",row.names = FALSE)
```

